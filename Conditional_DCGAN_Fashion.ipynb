{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4E109s868zM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Networks\n",
    "\n",
    "Implement conditional GAN as mentioned in [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) paper.\n",
    "\n",
    "We will use DCGAN architecture and modify for taking conditional input labels.\n",
    "\n",
    "\n",
    "### Let's start by imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1660866274850,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "5QOw6Dc4LShV",
    "outputId": "d9738b0d-a705-41b2-b981-dbfd45a49871",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tuAPnB67_cz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!unzip \"/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/Data/segImagesNew.zip\" -d \"/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1660866277154,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "B3P55qdC8DRq",
    "outputId": "10a4a256-31a6-417c-c547-2a40d6e88956",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0234694790>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import random\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1660866277154,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "Vl6bKG0C8JD5",
    "outputId": "99e00fef-7615-473f-8438-289251b0f0c1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda backend\n"
     ]
    }
   ],
   "source": [
    "# use cuda if available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "print(f\"Using {DEVICE} backend\")\n",
    "\n",
    "DATASET_NAME = \"FASHION\"  #@param {type:\"string\"}\n",
    "# batch size for training models \n",
    "# Change multiple of 16 only, else modify below code\n",
    "BATCH_SIZE = 10  #@param {type:\"integer\"}\n",
    "IMG_SIZE = 68  #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npKgap6npJaT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6krqsXd8Mkw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, json_data, root_dir, segments_dir, image_size, gen_img_sz):\n",
    "\n",
    "        self.gen_img_sz = gen_img_sz\n",
    "        self.meta_data = json_data\n",
    "        self.root_dir = root_dir\n",
    "        self.segments_dir = segments_dir\n",
    "        self.transformGen = torchvision.transforms.Compose(\n",
    "            [torchvision.transforms.Resize(size=(gen_img_sz, gen_img_sz)), torchvision.transforms.ToTensor(),\n",
    "             transforms.Normalize([0.5], [0.5])])\n",
    "        self.transformDis = torchvision.transforms.Compose(\n",
    "            [torchvision.transforms.Resize(size=(image_size, image_size)), torchvision.transforms.ToTensor(),\n",
    "             transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        filename = list(self.meta_data[idx].keys())[0]\n",
    "        # img_name = os.path.join(self.root_dir, filename)\n",
    "        img_name = self.root_dir + '/' + filename\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        gen_img = torch.randn(4, self.gen_img_sz, self.gen_img_sz)\n",
    "        labels = []\n",
    "        for img in self.meta_data[idx][filename]:\n",
    "            # segImage = Image.open(os.path.join(self.segments_dir,img['segImage']))\n",
    "            segImage = Image.open(self.segments_dir + '/' + img['segImage'])\n",
    "            gen_img = gen_img + self.transformGen(segImage)\n",
    "            labels.append(img['class'])\n",
    "\n",
    "        sample = {'image': self.transformDis(image), 'inputImage': gen_img}\n",
    "\n",
    "        return sample, self.get_lables(labels)\n",
    "\n",
    "    def get_lables(self, labels):\n",
    "        index = torch.tensor(labels)\n",
    "        labels = torch.zeros(1, 13).index_fill_(1, index, 1)\n",
    "        return labels.view(-1, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vUx6BKK8TEw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = \"/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/Data/train\"\n",
    "seg_dir = \"/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/Data/segImages\"\n",
    "\n",
    "f = open(\"/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/Data/metadata_train.json\")\n",
    "j_file = json.load(f)\n",
    "f.close()\n",
    "\n",
    "# train_data = FashionDataset(j_file[:50000], root_dir, seg_dir, 64 , 64)\n",
    "train_data = FashionDataset(j_file[:1000], root_dir, seg_dir, 68, 13)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N63GYpWeX_Wp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sam, lbl = train_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1660866304468,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "GIqQNN71B771",
    "outputId": "6fd55d09-33f0-498a-f16f-77a877e511e9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW4E-IV4y3Qn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Discriminator Model ( D )\n",
    "\n",
    "Discriminator is a binary classification model, which predicts if given image is generated one or taken from training data.\n",
    "\n",
    "Discriminator model will take a image and a class label. We will reshape class label to shape (batch_size, num_labels, 28, 28) and channel corresponding to image labels will have all ones and other all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttrXP45f8fi6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\" D(x) \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # initalize super module\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.linear_y = nn.Sequential(nn.Linear(13, 1024),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(1024, 3 * 68 * 68),\n",
    "                                      nn.Sigmoid()\n",
    "                                      )\n",
    "\n",
    "        self.linear_xy = nn.Sequential(nn.Linear(100, 1),\n",
    "                                       nn.Sigmoid()\n",
    "                                       )\n",
    "\n",
    "        # creating layer for image input , input size : (batch_size, 3, 64, 64)\n",
    "        self.layer_x = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32,\n",
    "                                               kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                                     # out size : (batch_size, 32, 32, 32)\n",
    "                                     nn.LeakyReLU(0.2, inplace=True),\n",
    "                                     # out size : (batch_size, 32, 32, 32)\n",
    "                                     )\n",
    "\n",
    "        # creating layer for label input, input size : (batch_size, 13, 64, 64)\n",
    "        self.layer_y = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32,\n",
    "                                               kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                                     # out size : (batch_size, 32, 32, 32)\n",
    "                                     nn.LeakyReLU(0.2, inplace=True),\n",
    "                                     # out size : (batch_size, 32, 32, 32)\n",
    "                                     )\n",
    "\n",
    "        # layer for concat of image layer and label layer, input size : (batch_size, 64, 32, 32)\n",
    "        self.layer_xy = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64,\n",
    "                                                kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                                      # out size : (batch_size, 128, 7, 7)\n",
    "                                      nn.BatchNorm2d(64),\n",
    "                                      # out size : (batch_size, 128, 7, 7)\n",
    "                                      nn.LeakyReLU(0.2, inplace=True),\n",
    "                                      # out size : (batch_size, 128, 7, 7)\n",
    "                                      nn.Conv2d(in_channels=64, out_channels=32,\n",
    "                                                kernel_size=3, stride=2, padding=0, bias=False),\n",
    "                                      # out size : (batch_size, 256, 3, 3)\n",
    "                                      nn.BatchNorm2d(32),\n",
    "                                      # out size : (batch_size, 256, 3, 3)\n",
    "                                      nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                                      nn.Conv2d(in_channels=32, out_channels=8,\n",
    "                                                kernel_size=3, stride=2, padding=0, bias=False),\n",
    "                                      # out size : (batch_size, 256, 3, 3)\n",
    "                                      nn.BatchNorm2d(8),\n",
    "                                      # out size : (batch_size, 256, 3, 3)\n",
    "                                      nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "                                      #  # out size : (batch_size, 256, 3, 3)\n",
    "                                      #  # Notice in below layer, we are using out channels as 1, we don't need to use Linear layer\n",
    "                                      #  # Same is recommended in DCGAN paper also\n",
    "                                      nn.Conv2d(in_channels=8, out_channels=1,\n",
    "                                                kernel_size=3, stride=3, padding=0, bias=False),\n",
    "\n",
    "                                      #  # out size : (batch_size, 1, 1, 1)\n",
    "                                      #  # sigmoid layer to convert in [0,1] range\n",
    "\n",
    "                                      nn.Sigmoid()\n",
    "                                      )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        y = self.linear_y(y)\n",
    "        y = y.view(x.shape[0], x.shape[1], x.shape[2], x.shape[3])\n",
    "\n",
    "        # size of x : (batch_size, 1, 64, 64)\n",
    "        x = self.layer_x(x)\n",
    "\n",
    "        # print(\"Y: \", x.shape)\n",
    "        # size of x : (batch_size, 32, 32, 32)\n",
    "\n",
    "        # size of y : (batch_size, 13, 64, 64)\n",
    "        y = self.layer_y(y)\n",
    "        # print(\"y: \", y.shape)\n",
    "        # # size of y : (batch_size, 32, 32, 32)\n",
    "\n",
    "        # concat image layer and label layer output\n",
    "        xy = torch.cat([x, y], dim=1)\n",
    "        # size of xy : (batch_size, 64, 32, 32)\n",
    "        xy = self.layer_xy(xy)\n",
    "        # print(\"xy: \", xy.shape)\n",
    "        # # size of xy : (batch_size, 1, 1, 1)\n",
    "        xy = xy.view(xy.shape[0], -1)\n",
    "        # # size of xy : (batch_size, 1)\n",
    "        # xy = self.linear_xy(xy)\n",
    "        return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4659,
     "status": "ok",
     "timestamp": 1660866314019,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "cazn6Yf98ihF",
    "outputId": "082182fb-eb81-4e04-ded7-211049069600",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discriminator(\n",
      "  (linear_y): Sequential(\n",
      "    (0): Linear(in_features=13, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=13872, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      "  (linear_xy): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (layer_x): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (layer_y): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (layer_xy): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 8, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(8, 1, kernel_size=(3, 3), stride=(3, 3), bias=False)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator().to(DEVICE)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing NetD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQDbFqqqCZZs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_x = torch.randn(1, 3, 68, 68).to(DEVICE)\n",
    "input_y = torch.randn(1, 1, 13).view(-1, 13).to(DEVICE)\n",
    "out_xy = netD(input_x, input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660838863012,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "N-Nqa1xLB7Kn",
    "outputId": "d94ac508-b841-4738-dac0-d3912992d6b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "[1, 1132096]\n",
    "[1, 139392]\n",
    "out_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RI6XaQwyJ98q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1660838863180,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "cDnuZlk3Klrz",
    "outputId": "4ca81713-2c76-4108-a0fb-5c358acf42f6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0.4124, 0.7190, 0.1609], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0., 0., 0.]))"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "m(input), target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zm6hsLk4kHv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generator Model ( G )\n",
    "\n",
    "Aim of the generator is to fool the discriminator model. Generator will take random noise ( latent vector) z and label for which image need to be generated. Label will be passed as onehot encoding.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5C5Ix7Z8l8N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.activation import Softmax\n",
    "from torch.nn.modules import linear\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\" G(z) \"\"\"\n",
    "\n",
    "    def __init__(self, input_size=100):\n",
    "        # initalize super module\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # embedded layer for y(conditional input)\n",
    "        self.linear_y = nn.Sequential(nn.Linear(689, 507),\n",
    "                                      nn.LeakyReLU(),\n",
    "\n",
    "                                      self.layer_xy = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=5,\n",
    "                               stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=2, out_channels=2, kernel_size=5,\n",
    "                               stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=2, out_channels=2, kernel_size=5,\n",
    "                               stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=2, out_channels=3, kernel_size=4,\n",
    "                               stride=1, padding=0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            b_sz = x.shape[0]\n",
    "            x = x.flatten()\n",
    "            y = y.flatten()\n",
    "\n",
    "            xy = torch.cat([x, y], dim=-1).view(b_sz, 1, -1)\n",
    "            xy = self.linear_y(xy)\n",
    "\n",
    "            xy = self.layer_xy(xy.view(b_sz, 3, 13, 13))\n",
    "            # print(xy.shape)\n",
    "            # xy = self.linear_xy(xy.view(b_sz,-1, 1870 * 1870))\n",
    "            return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1660838863181,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "csfqJLdh8oSI",
    "outputId": "1231f7d7-fb15-4c28-e6f2-5670e3c4a388",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generator(\n",
      "  (linear_y): Sequential(\n",
      "    (0): Linear(in_features=689, out_features=507, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (layer_xy): Sequential(\n",
      "    (0): ConvTranspose2d(3, 2, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): ConvTranspose2d(2, 2, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=True)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): ConvTranspose2d(2, 2, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=True)\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): ConvTranspose2d(2, 3, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Generator\n",
    "netG = Generator().to(DEVICE)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing netG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOhU208CMvhZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_x = torch.randn(2, 4, 64, 64).view(2, -1, 4*64*64).to(DEVICE)\n",
    "input_x = torch.randn(2, 4, 13, 13).to(DEVICE)\n",
    "input_y = torch.randn(2, 1, 1, 13).view(-1, 13).to(DEVICE)\n",
    "out_xy = netG(input_x, input_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1660838863181,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "NCFPVj0-M-z0",
    "outputId": "9e6e6b34-1abe-43d3-c692-929440a038b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 68, 68])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "out_xy.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6YXrnydFPc-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Weight Initalization \n",
    "From the DCGAN paper, the authors specify that all model weights shall be randomly initialized from a Normal distribution with mean=0, stdev=0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6mHiuWp8sOi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# custom weights initialization\n",
    "def weights_init(net):\n",
    "    classname = net.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(net.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(net.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(net.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660838863181,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "gI53g7ah8u-f",
    "outputId": "238b1a4f-44f7-47c6-a0c5-3f27702c2d78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear_y): Sequential(\n",
       "    (0): Linear(in_features=689, out_features=507, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (layer_xy): Sequential(\n",
       "    (0): ConvTranspose2d(3, 2, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): ConvTranspose2d(2, 2, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
       "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): ConvTranspose2d(2, 2, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=True)\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): ConvTranspose2d(2, 3, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "# randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_fmu5lBUdPv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Training\n",
    "\n",
    "\n",
    "\n",
    "*   Value of beta1 hyperparameter in Adam optimizer has huge impact on stability of generator and DCGAN paper recommend 0.5 value.\n",
    "*   Recommended learning rate for Adam is 0.0002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDu128c28yWx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of training epochs\n",
    "NUM_EPOCH = 100  #@param {type:\"integer\"}\n",
    "# number of discriminator steps for each generator step\n",
    "Ksteps = 1  #@param {type:\"integer\"}\n",
    "# learning rate of adam\n",
    "# DCGAN recommend 0.0002 lr\n",
    "Adam_lr = 0.0002  #@param {type:\"number\"}\n",
    "# DCGAN recommend 0.5\n",
    "Adam_beta1 = 0.5  #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9V6SiTY81L_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We calculate Binary cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "# Adam optimizer for generator \n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=Adam_lr, betas=(Adam_beta1, 0.999))\n",
    "# Adam optimizer for discriminator \n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=Adam_lr, betas=(Adam_beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtnRTzkr85jD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# labels for training images x for Discriminator training\n",
    "labels_real = torch.ones((BATCH_SIZE, 1)).to(DEVICE)\n",
    "# labels for generated images G(z) for Discriminator training\n",
    "labels_fake = torch.zeros((BATCH_SIZE, 1)).to(DEVICE)\n",
    "# Fix noise for testing generator and visualization\n",
    "z_test = torch.randn(68, 68).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IrFAll688Pt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample, lbl = train_data[200]\n",
    "test_Gy = lbl.to(DEVICE)\n",
    "z_test = torch.randn(3, 13, 13, device=DEVICE)\n",
    "z_test = sample['inputImage'].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1660838863330,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     },
     "user_tz": 240
    },
    "id": "uV5TJ_qoTPaa",
    "outputId": "74a5fd55-5b7e-40a4-c7d8-fd2271d9c177",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "test_Gy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9fK-GL68_m3",
    "outputId": "cdbe3559-b982-43ea-9029-a4eb4ec188c4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1660853425600,
     "user_tz": 240,
     "elapsed": 5753327,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Epoch 1/100 Discriminator Loss 0.005 Generator Loss 7.560 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 2/100 Discriminator Loss 0.049 Generator Loss 7.463 D(x) 0.993 D(G(x)) 0.007\n",
      " Epoch 3/100 Discriminator Loss 0.021 Generator Loss 8.252 D(x) 0.995 D(G(x)) 0.004\n",
      " Epoch 4/100 Discriminator Loss 0.030 Generator Loss 7.982 D(x) 0.994 D(G(x)) 0.003\n",
      " Epoch 5/100 Discriminator Loss 0.013 Generator Loss 8.508 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 6/100 Discriminator Loss 0.022 Generator Loss 8.353 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 7/100 Discriminator Loss 0.005 Generator Loss 8.688 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 8/100 Discriminator Loss 0.003 Generator Loss 8.145 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 9/100 Discriminator Loss 0.016 Generator Loss 9.085 D(x) 0.996 D(G(x)) 0.002\n",
      " Epoch 10/100 Discriminator Loss 0.002 Generator Loss 8.822 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 11/100 Discriminator Loss 0.027 Generator Loss 8.300 D(x) 0.996 D(G(x)) 0.002\n",
      " Epoch 12/100 Discriminator Loss 0.004 Generator Loss 8.395 D(x) 0.998 D(G(x)) 0.001\n",
      " Epoch 13/100 Discriminator Loss 0.001 Generator Loss 9.714 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 14/100 Discriminator Loss 0.001 Generator Loss 8.862 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 15/100 Discriminator Loss 0.000 Generator Loss 9.852 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 16/100 Discriminator Loss 0.000 Generator Loss 10.499 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 17/100 Discriminator Loss 0.000 Generator Loss 10.583 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 18/100 Discriminator Loss 0.000 Generator Loss 10.417 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 19/100 Discriminator Loss 0.000 Generator Loss 11.368 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 20/100 Discriminator Loss 0.027 Generator Loss 9.467 D(x) 0.999 D(G(x)) 0.002\n",
      " Epoch 21/100 Discriminator Loss 0.001 Generator Loss 9.141 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 22/100 Discriminator Loss 0.042 Generator Loss 10.062 D(x) 0.997 D(G(x)) 0.005\n",
      " Epoch 23/100 Discriminator Loss 0.032 Generator Loss 9.510 D(x) 0.994 D(G(x)) 0.002\n",
      " Epoch 24/100 Discriminator Loss 0.011 Generator Loss 7.907 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 25/100 Discriminator Loss 0.002 Generator Loss 9.153 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 26/100 Discriminator Loss 0.006 Generator Loss 9.742 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 27/100 Discriminator Loss 0.002 Generator Loss 8.387 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 28/100 Discriminator Loss 0.001 Generator Loss 9.276 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 29/100 Discriminator Loss 0.016 Generator Loss 10.072 D(x) 0.999 D(G(x)) 0.002\n",
      " Epoch 30/100 Discriminator Loss 0.002 Generator Loss 8.850 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 31/100 Discriminator Loss 0.029 Generator Loss 8.464 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 32/100 Discriminator Loss 0.001 Generator Loss 9.061 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 33/100 Discriminator Loss 0.010 Generator Loss 8.980 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 34/100 Discriminator Loss 0.001 Generator Loss 9.828 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 35/100 Discriminator Loss 0.000 Generator Loss 9.425 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 36/100 Discriminator Loss 0.000 Generator Loss 9.787 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 37/100 Discriminator Loss 0.016 Generator Loss 9.985 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 38/100 Discriminator Loss 0.009 Generator Loss 9.038 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 39/100 Discriminator Loss 0.006 Generator Loss 8.875 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 40/100 Discriminator Loss 0.001 Generator Loss 11.222 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 41/100 Discriminator Loss 0.000 Generator Loss 9.243 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 42/100 Discriminator Loss 0.000 Generator Loss 9.122 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 43/100 Discriminator Loss 0.028 Generator Loss 8.558 D(x) 0.995 D(G(x)) 0.002\n",
      " Epoch 44/100 Discriminator Loss 0.007 Generator Loss 7.797 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 45/100 Discriminator Loss 0.002 Generator Loss 7.924 D(x) 1.000 D(G(x)) 0.001\n",
      " Epoch 46/100 Discriminator Loss 0.001 Generator Loss 9.333 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 47/100 Discriminator Loss 0.021 Generator Loss 9.853 D(x) 0.999 D(G(x)) 0.002\n",
      " Epoch 48/100 Discriminator Loss 0.001 Generator Loss 7.796 D(x) 1.000 D(G(x)) 0.001\n",
      " Epoch 49/100 Discriminator Loss 0.001 Generator Loss 9.109 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 50/100 Discriminator Loss 0.000 Generator Loss 9.875 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 51/100 Discriminator Loss 0.041 Generator Loss 9.390 D(x) 0.996 D(G(x)) 0.005\n",
      " Epoch 52/100 Discriminator Loss 0.015 Generator Loss 8.177 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 53/100 Discriminator Loss 0.016 Generator Loss 9.379 D(x) 0.996 D(G(x)) 0.002\n",
      " Epoch 54/100 Discriminator Loss 0.007 Generator Loss 9.563 D(x) 0.997 D(G(x)) 0.001\n",
      " Epoch 55/100 Discriminator Loss 0.012 Generator Loss 10.365 D(x) 0.997 D(G(x)) 0.001\n",
      " Epoch 56/100 Discriminator Loss 0.021 Generator Loss 9.793 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 57/100 Discriminator Loss 0.021 Generator Loss 8.049 D(x) 0.995 D(G(x)) 0.003\n",
      " Epoch 58/100 Discriminator Loss 0.010 Generator Loss 9.834 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 59/100 Discriminator Loss 0.006 Generator Loss 9.896 D(x) 0.999 D(G(x)) 0.002\n",
      " Epoch 60/100 Discriminator Loss 0.013 Generator Loss 8.479 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 61/100 Discriminator Loss 0.015 Generator Loss 7.652 D(x) 0.995 D(G(x)) 0.004\n",
      " Epoch 62/100 Discriminator Loss 0.036 Generator Loss 8.090 D(x) 0.992 D(G(x)) 0.004\n",
      " Epoch 63/100 Discriminator Loss 0.003 Generator Loss 8.718 D(x) 0.998 D(G(x)) 0.001\n",
      " Epoch 64/100 Discriminator Loss 0.047 Generator Loss 7.900 D(x) 0.991 D(G(x)) 0.003\n",
      " Epoch 65/100 Discriminator Loss 0.014 Generator Loss 9.319 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 66/100 Discriminator Loss 0.015 Generator Loss 8.640 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 67/100 Discriminator Loss 0.013 Generator Loss 9.049 D(x) 0.997 D(G(x)) 0.003\n",
      " Epoch 68/100 Discriminator Loss 0.021 Generator Loss 8.922 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 69/100 Discriminator Loss 0.015 Generator Loss 6.977 D(x) 0.996 D(G(x)) 0.004\n",
      " Epoch 70/100 Discriminator Loss 0.004 Generator Loss 7.689 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 71/100 Discriminator Loss 0.033 Generator Loss 7.905 D(x) 0.990 D(G(x)) 0.007\n",
      " Epoch 72/100 Discriminator Loss 0.016 Generator Loss 8.686 D(x) 0.996 D(G(x)) 0.003\n",
      " Epoch 73/100 Discriminator Loss 0.038 Generator Loss 8.526 D(x) 0.992 D(G(x)) 0.006\n",
      " Epoch 74/100 Discriminator Loss 0.011 Generator Loss 9.096 D(x) 0.996 D(G(x)) 0.002\n",
      " Epoch 75/100 Discriminator Loss 0.005 Generator Loss 9.789 D(x) 0.998 D(G(x)) 0.001\n",
      " Epoch 76/100 Discriminator Loss 0.021 Generator Loss 7.098 D(x) 0.997 D(G(x)) 0.004\n",
      " Epoch 77/100 Discriminator Loss 0.031 Generator Loss 8.782 D(x) 0.996 D(G(x)) 0.004\n",
      " Epoch 78/100 Discriminator Loss 0.013 Generator Loss 8.682 D(x) 0.996 D(G(x)) 0.001\n",
      " Epoch 79/100 Discriminator Loss 0.014 Generator Loss 10.499 D(x) 0.995 D(G(x)) 0.001\n",
      " Epoch 80/100 Discriminator Loss 0.041 Generator Loss 8.877 D(x) 0.990 D(G(x)) 0.006\n",
      " Epoch 81/100 Discriminator Loss 0.006 Generator Loss 9.631 D(x) 0.997 D(G(x)) 0.001\n",
      " Epoch 82/100 Discriminator Loss 0.003 Generator Loss 9.330 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 83/100 Discriminator Loss 0.023 Generator Loss 10.018 D(x) 0.995 D(G(x)) 0.003\n",
      " Epoch 84/100 Discriminator Loss 0.004 Generator Loss 9.065 D(x) 0.998 D(G(x)) 0.001\n",
      " Epoch 85/100 Discriminator Loss 0.022 Generator Loss 10.105 D(x) 0.994 D(G(x)) 0.004\n",
      " Epoch 86/100 Discriminator Loss 0.035 Generator Loss 9.517 D(x) 0.992 D(G(x)) 0.003\n",
      " Epoch 87/100 Discriminator Loss 0.011 Generator Loss 9.881 D(x) 0.996 D(G(x)) 0.001\n",
      " Epoch 88/100 Discriminator Loss 0.006 Generator Loss 10.258 D(x) 0.997 D(G(x)) 0.001\n",
      " Epoch 89/100 Discriminator Loss 0.002 Generator Loss 9.583 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 90/100 Discriminator Loss 0.001 Generator Loss 9.491 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 91/100 Discriminator Loss 0.025 Generator Loss 10.319 D(x) 0.997 D(G(x)) 0.002\n",
      " Epoch 92/100 Discriminator Loss 0.003 Generator Loss 9.214 D(x) 0.999 D(G(x)) 0.001\n",
      " Epoch 93/100 Discriminator Loss 0.007 Generator Loss 10.404 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 94/100 Discriminator Loss 0.002 Generator Loss 10.023 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 95/100 Discriminator Loss 0.017 Generator Loss 10.677 D(x) 0.998 D(G(x)) 0.002\n",
      " Epoch 96/100 Discriminator Loss 0.002 Generator Loss 9.630 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 97/100 Discriminator Loss 0.001 Generator Loss 10.039 D(x) 1.000 D(G(x)) 0.000\n",
      " Epoch 98/100 Discriminator Loss 0.001 Generator Loss 12.204 D(x) 0.999 D(G(x)) 0.000\n",
      " Epoch 99/100 Discriminator Loss 0.007 Generator Loss 10.024 D(x) 0.999 D(G(x)) 0.002\n",
      " Epoch 100/100 Discriminator Loss 0.001 Generator Loss 9.615 D(x) 1.000 D(G(x)) 0.000\n"
     ]
    }
   ],
   "source": [
    "# List of values, which will be used for plotting purpose\n",
    "D_losses = []\n",
    "G_losses = []\n",
    "Dx_values = []\n",
    "DGz_values = []\n",
    "img_list = []\n",
    "# number of training steps done on discriminator \n",
    "step = 0\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    epoch_D_losses = []\n",
    "    epoch_G_losses = []\n",
    "    epoch_Dx = []\n",
    "    epoch_DGz = []\n",
    "    # iterate through data loader generator object\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        images, y_labels = data\n",
    "        step += 1\n",
    "        ############################\n",
    "        # Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # images will be send to gpu, if cuda available\n",
    "        x = images['image'].to(DEVICE)\n",
    "\n",
    "        D_y = y_labels.to(DEVICE)\n",
    "\n",
    "        # forward pass D(x)\n",
    "        x_preds = netD(x, D_y)\n",
    "\n",
    "        # calculate loss log(D(x))\n",
    "        D_x_loss = criterion(x_preds, labels_real)\n",
    "\n",
    "        # create latent vector z from normal distribution\n",
    "        z = images['inputImage'].to(DEVICE)\n",
    "        G_y = y_labels.to(DEVICE)\n",
    "\n",
    "        # generate image\n",
    "        fake_image = netG(z, G_y)\n",
    "        # calculate D(G(z)), fake or not\n",
    "        z_preds = netD(fake_image.detach(), G_y)\n",
    "\n",
    "        # loss log(1 - D(G(z)))\n",
    "        D_z_loss = criterion(z_preds, labels_fake)\n",
    "\n",
    "        # total loss = log(D(x)) + log(1 - D(G(z)))\n",
    "        D_loss = D_x_loss + D_z_loss\n",
    "\n",
    "        # save values for plots\n",
    "        epoch_D_losses.append(D_loss.item())\n",
    "        epoch_Dx.append(x_preds.mean().item())\n",
    "\n",
    "        # zero accumalted grads\n",
    "        netD.zero_grad()\n",
    "        # do backward pass\n",
    "        D_loss.backward()\n",
    "        # update discriminator model\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        # if Ksteps of Discriminator training are done, update generator\n",
    "        if step % Ksteps == 0:\n",
    "            # As we done one step of discriminator, again calculate D(G(z))\n",
    "            z_out = netD(fake_image, G_y)\n",
    "\n",
    "            # loss log(D(G(z)))\n",
    "            G_loss = criterion(z_out, labels_real)\n",
    "            # G_loss = -torch.mean(z_out)\n",
    "\n",
    "            # save values for plots\n",
    "            epoch_DGz.append(z_out.mean().item())\n",
    "            epoch_G_losses.append(G_loss)\n",
    "\n",
    "            # zero accumalted grads\n",
    "            netG.zero_grad()\n",
    "            # do backward pass\n",
    "            G_loss.backward()\n",
    "            # update generator model\n",
    "            optimizerG.step()\n",
    "    else:\n",
    "        # calculate average value for one epoch\n",
    "        D_losses.append(sum(epoch_D_losses) / len(epoch_D_losses))\n",
    "        G_losses.append(sum(epoch_G_losses) / len(epoch_G_losses))\n",
    "        Dx_values.append(sum(epoch_Dx) / len(epoch_Dx))\n",
    "        DGz_values.append(sum(epoch_DGz) / len(epoch_DGz))\n",
    "\n",
    "        print(f\" Epoch {epoch + 1}/{NUM_EPOCH} Discriminator Loss {D_losses[-1]:.3f} Generator Loss {G_losses[-1]:.3f}\"\n",
    "              + f\" D(x) {Dx_values[-1]:.3f} D(G(x)) {DGz_values[-1]:.3f}\")\n",
    "\n",
    "        # Generating images after each epoch and saving\n",
    "        # set generator to evaluation mode\n",
    "        netG.eval()\n",
    "\n",
    "        if (step % 50 == 0) and (i == len(dataloader) - 1):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(z_test.view(1, 4, 13, 13), test_Gy.view(1, 1, 13)).cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        netG.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD0jTPLKZzTu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "After 20 epoch training, we are able to generate quite good images."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# torch.save(netG.state_dict(), '/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/netG.pt')\n",
    "# torch.save(netD.state_dict(), '/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/netD.pt')"
   ],
   "metadata": {
    "id": "gtCJvap5xZEP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and test Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Generator().to(DEVICE)\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/GBC/Friends/Capstone_Project/Fashion/netG.pt'))\n",
    "model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-W3YvUJ_bxv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1660866599501,
     "user_tz": 240,
     "elapsed": 130,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     }
    },
    "outputId": "4747d3f7-a2e5-4a02-df5a-acb2904704b1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear_y): Sequential(\n",
       "    (0): Linear(in_features=689, out_features=507, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (layer_xy): Sequential(\n",
       "    (0): ConvTranspose2d(3, 2, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): ConvTranspose2d(2, 2, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
       "    (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): ConvTranspose2d(2, 2, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=True)\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): ConvTranspose2d(2, 3, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAy4cVZpjz2O",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(1000, size=1)[0]\n",
    "sample, lbl = train_data[i]\n",
    "test_Gy = lbl.to(DEVICE)\n",
    "z_test = sample['inputImage'].to(DEVICE)\n",
    "\n",
    "fake2 = model(z_test.view(1, 4, 13, 13), test_Gy.view(1, 1, 13)).cpu()\n",
    "img = vutils.make_grid(fake2, padding=2, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## plot generated Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "W1YdBN1yh-Ym",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1660866654782,
     "user_tz": 240,
     "elapsed": 288,
     "user": {
      "displayName": "Frederick Atiah",
      "userId": "02989612204172587808"
     }
    },
    "outputId": "870b5db2-7e74-48e4-d399-8633aedd8a9b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0220069ed0>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(np.transpose(img, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### Plot for Discriminator and Generator loss over the epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SYmpS43GRQH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Discriminator and Generator loss during Training\")\n",
    "# plot Discriminator and generator loss\n",
    "plt.plot(D_losses, label=\"D Loss\")\n",
    "plt.plot(G_losses, label=\"G Loss\")\n",
    "# get plot axis\n",
    "ax = plt.gca()\n",
    "# remove right and top spine\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# add labels and create legend\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Conditional_DCGAN_Fashion.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}